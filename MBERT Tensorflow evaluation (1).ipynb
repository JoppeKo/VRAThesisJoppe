{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e54c36-e28e-4d70-acd3-659d447b6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956622ee-976e-4f35-9732-45db2311cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('hpc_space/test_data_5_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a471e7f-3b58-4bed-8fce-05d254b82464",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('hpc_space/val_data_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45443d42-a310-43ef-a14e-781b8db1b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(text):\n",
    "    text = re.sub(\"'\", \"\", text)\n",
    "    text = re.sub(\"(\\\\W)+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5f70a-2b82-4fa1-bdb8-7030f9307be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['text'] = test_data.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384480e6-a066-4d60-8918-af6ceff1f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['text'] = val_data.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a69390-8b7c-4796-aef5-74c988b6bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_gendered_words(text, gender):\n",
    "#     gendered_word_mapping = {\n",
    "#         0: {\"zij\": \"hij\", \"Zij\": \"Hij\", \"ze\": \"hij\", \"Ze\": \"Hij\", \"haar\": \"hem\", \"Haar\": \"Hem\", \"mw\": \"dhr\", \"Mw\": \"Dhr\", \"vrouw\": \"man\", \"Vrouw\": \"Man\", \"patiente\": \"patient\", \"Patiente\": \"Patient\", \"mevrouw\": \"meneer\", \"Mevrouw\": \"Meneer\", \"mevr\": \"mr\", \"Mevr\": \"Mr\", \"meisje\": \"jongen\", \"Meisje\": \"Jongen\", \"dame\": \"heer\", \"Dame\": \"Heer\"},\n",
    "#         1: {\"hij\": \"zij\", \"Hij\": \"Zij\", \"hem\": \"haar\", \"Hem\": \"Haar\", \"zijn\": \"haar\", \"Zijn\":\"Haar\", \"dhr\": \"mw\", \"Dhr\": \"Mw\", \"man\": \"vrouw\", \"Man\": \"Vrouw\", \"patient\": \"patiente\", \"Patient\": \"Patiente\", \"meneer\": \"mevrouw\", \"Meneer\": \"Mevrouw\", \"mr\": \"mevr\", \"Mr\": \"Mevr\", \"jongen\": \"meisje\", \"Jongen\": \"Meisje\", \"heer\": \"dame\", \"Heer\": \"Dame\", \"hr\":\"mw\", \"Hr\": \"Mw\"},\n",
    "#     }\n",
    "\n",
    "#     words = text.split()\n",
    "\n",
    "#     for i in range(len(words)):\n",
    "#         word = words[i]\n",
    "#         if word in gendered_word_mapping[gender]:\n",
    "#             words[i] = gendered_word_mapping[gender][word]\n",
    "\n",
    "#     return ' '.join(words)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # Replace gendered words in the 'text' column based on the 'Geslacht' column\n",
    "#     test_data['text'] = test_data.apply(lambda row: replace_gendered_words(row['text'], row['Geslacht']), axis=1)\n",
    "\n",
    "#     # Print the modified DataFrame\n",
    "#     print(\"Modified DataFrame:\")\n",
    "#     print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d4297-4732-45b2-8276-94fda51709b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['Geslacht'] = test_data['Geslacht'].replace({0: 1, 1: 0})\n",
    "\n",
    "# # Print the modified DataFrame\n",
    "# print(\"Modified DataFrame:\")\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cbb27-f217-43c3-8ed4-996c0c3fbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['Combined'] = test_data['Combined'].replace({'0_1': '0_0', '0_0': '0_1', '1_0': '1_1', '1_1': '1_0'})\n",
    "\n",
    "# # Print the modified DataFrame\n",
    "# print(\"Modified DataFrame:\")\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472cf2c-8a3d-4694-968b-5202bbf00d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_orig = pd.read_csv('hpc_space/MBERT1/test_data_mid_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49601fc6-1d74-42cb-bc83-acb9dcbb3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_orig['text'] = test_data_orig.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ead85f-6baa-476c-9c8a-99dc061e1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.concat([test_data_orig, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f245b-80ef-4248-ae67-03ddd5940732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "    l_total = []\n",
    "    chunk_size = 500\n",
    "    overlap = 50\n",
    "\n",
    "    words = text1.split()\n",
    "\n",
    "    for start_idx in range(0, len(words), chunk_size - overlap):\n",
    "        end_idx = start_idx + chunk_size\n",
    "        l_parcial = words[start_idx:end_idx]\n",
    "        l_total.append(\" \".join(l_parcial))\n",
    "\n",
    "    return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef148cbe-940b-407c-9852-603c0fb7cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:, 'text_split'] = test_data['text'].apply(get_split)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6b0f5-762d-472f-9520-b75b4bd8e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.loc[:, 'text_split'] = val_data['text'].apply(get_split)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96791b6f-e771-4f19-994f-ba13e2f1ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = []\n",
    "test_label_l = []\n",
    "test_index_l = []\n",
    "geslacht_l = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    for l in row['text_split']:\n",
    "        test_l.append(l)\n",
    "        test_label_l.append(row['outcome'])\n",
    "        test_index_l.append(idx)\n",
    "        geslacht_l.append(row['Geslacht'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d03e1e-01e6-495a-b0ef-c69752907bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "val_geslacht_l = []\n",
    "for idx, row in val_data.iterrows():\n",
    "    for l in row['text_split']:\n",
    "        val_l.append(l)\n",
    "        val_label_l.append(row['outcome'])\n",
    "        val_index_l.append(idx)\n",
    "        val_geslacht_l.append(row['Geslacht'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7aba7-31df-4d2c-bafd-f15831de90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'text':test_l, 'label':test_label_l, 'Geslacht':geslacht_l, 'original_index':test_index_l})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f01215-5643-42ab-a113-fc6d8a24c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame({'text':val_l, 'label':val_label_l, 'Geslacht':val_geslacht_l, 'original_index':val_index_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fb52d-c6bd-4127-b900-bfa2397b059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f48a2-daea-41c5-a2d6-7f5da62183a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "test_texts = test_df['text'].tolist()\n",
    "encoded_test = tokenizer(test_texts, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66329185-64cb-4c25-8e6b-f143acc364a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "# Set batch size and sequence length\n",
    "\n",
    "batch_size = 16\n",
    "max_seq_length = 512\n",
    "\n",
    "test_df_with_predictions = test_df.copy()\n",
    "\n",
    "# Convert PyTorch tensors to TensorFlow tensors in batches\n",
    "num_samples = len(test_texts)\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_input_ids = tf.convert_to_tensor(encoded_test['input_ids'][i:i+batch_size])\n",
    "    batch_attention_mask = tf.convert_to_tensor(encoded_test['attention_mask'][i:i+batch_size])\n",
    "    batch_token_type_ids = tf.convert_to_tensor(encoded_test['token_type_ids'][i:i+batch_size])\n",
    "\n",
    "    # Get model predictions for the current batch\n",
    "\n",
    "    logits = model(batch_input_ids, attention_mask=batch_attention_mask, token_type_ids=batch_token_type_ids).logits\n",
    "\n",
    "    # Convert logits to probabilities and labels\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    predicted_labels = tf.argmax(probs, axis=1)\n",
    "\n",
    "    # Update test_df_with_predictions with the current batch's predictions\n",
    "    batch_indices = list(range(i, min(i + batch_size, num_samples)))\n",
    "    for idx, label, prob in zip(batch_indices, predicted_labels.numpy(), np.max(probs.numpy(), axis=1)):\n",
    "        test_df_with_predictions.at[idx, 'predicted_label'] = label\n",
    "        test_df_with_predictions.at[idx, 'predicted_probability'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a22c62-05be-499a-99ce-2fc7034ef73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions.drop(['text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e8efc-8f60-4f97-aa12-c5682bfcdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions.rename(columns={'predicted_probability': 'predicted_probabilities'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7fa69f-9d91-43e1-8d24-d9c71a0e8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df_with_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e69e1-4b26-4f82-8c96-5933b515fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions.to_csv('BERTje_augmented5_chunk_augmentedtest_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6418325-1996-4002-9022-50c566e20592",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "val_texts = val_df['text'].tolist()\n",
    "encoded_val = tokenizer(val_texts, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80957b89-41a6-428a-8256-5b3559cc6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "# Set batch size and sequence length\n",
    "\n",
    "batch_size = 16\n",
    "max_seq_length = 512\n",
    "\n",
    "val_df_with_predictions = val_df.copy()\n",
    "\n",
    "# Convert PyTorch tensors to TensorFlow tensors in batches\n",
    "num_samples = len(val_texts)\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_input_ids = tf.convert_to_tensor(encoded_val['input_ids'][i:i+batch_size])\n",
    "    batch_attention_mask = tf.convert_to_tensor(encoded_val['attention_mask'][i:i+batch_size])\n",
    "    batch_token_type_ids = tf.convert_to_tensor(encoded_val['token_type_ids'][i:i+batch_size])\n",
    "\n",
    "    # Get model predictions for the current batch\n",
    "\n",
    "    logits = model(batch_input_ids, attention_mask=batch_attention_mask, token_type_ids=batch_token_type_ids).logits\n",
    "\n",
    "    # Convert logits to probabilities and labels\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    predicted_labels = tf.argmax(probs, axis=1)\n",
    "\n",
    "    # Update val_df_with_predictions with the current batch's predictions\n",
    "    batch_indices = list(range(i, min(i + batch_size, num_samples)))\n",
    "    for idx, label, prob in zip(batch_indices, predicted_labels.numpy(), np.max(probs.numpy(), axis=1)):\n",
    "        val_df_with_predictions.at[idx, 'predicted_label'] = label\n",
    "        val_df_with_predictions.at[idx, 'predicted_probability'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a5c3c-f0ce-423b-a295-fb27de50f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_with_predictions.drop(['text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f999c-d330-4f27-8730-18fa1a220fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_with_predictions.rename(columns={'predicted_probability': 'predicted_probabilities'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e1138-85a4-4e3b-b198-ed0014e328d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_df_with_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f47a74-5036-4e05-9b1b-048e5e83b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_with_predictions.to_csv('BERTje_augmented5_chunk_val_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524c36f-3ec0-46c1-9f5b-0895d3e61c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bc2bd-720b-423e-b6c2-d5b1fc9506d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac406945-b06e-4117-998b-456b0fcab3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5ae1c-1f64-41a7-8e2c-20c24a01da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the predicted labels based on 'original_index'\n",
    "grouped_predictions = test_df_with_predictions.groupby('original_index')['predicted_label'].apply(list)\n",
    "\n",
    "# Merge the grouped predictions back to the original DataFrame\n",
    "merged_df = test_df_with_predictions.merge(grouped_predictions, left_on='original_index', right_index=True)\n",
    "\n",
    "# Rename the new column\n",
    "merged_df.rename(columns={'predicted_label_y': 'grouped_predicted_labels'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df.drop(['text', 'predicted_label_x'], axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicates and keep only one row per unique original_index\n",
    "final_df = merged_df.drop_duplicates(subset='original_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a54c7-95f0-43ba-b98f-1fd9ae8b1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('hpc_space/Results/temp/' + 'BERTje_genderneutral_predictions_1_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9939f9-5a44-4b54-9b52-084dd2f0bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"hpc_space/Results/temp/BERTje_genderneutral_predictions_1_temp.csv\")\n",
    "# Convert string representations of lists to actual lists\n",
    "final_df['grouped_predicted_labels'] = final_df['grouped_predicted_labels'].apply(eval)\n",
    "\n",
    "# Function to determine final prediction\n",
    "def calculate_final_prediction(grouped_labels):\n",
    "    # Calculate the proportion of 1s in the grouped labels\n",
    "    proportion_of_ones = grouped_labels.count(1) / len(grouped_labels)\n",
    "\n",
    "    # Set the threshold for making the final prediction\n",
    "    threshold = 0.25\n",
    "\n",
    "    # Make the final prediction based on the proportion\n",
    "    if proportion_of_ones > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to each row and create a new column for final predictions\n",
    "final_df['final_prediction'] = final_df['grouped_predicted_labels'].apply(calculate_final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5d061-6ec8-438d-8427-f909beb73a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Calculate accuracy for the positive class (label = 1)\n",
    "accuracy_positive = accuracy_score(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate precision for the positive class (label = 1)\n",
    "precision_positive = precision_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate recall for the positive class (label = 1)\n",
    "recall_positive = recall_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate F1 score for the positive class (label = 1)\n",
    "f1_positive = f1_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate precision for the negative class (label = 0)\n",
    "precision_negative = precision_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate recall for the negative class (label = 0)\n",
    "recall_negative = recall_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate F1 score for the negative class (label = 0)\n",
    "f1_negative = f1_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate the AUC for males (Geslacht = 1)\n",
    "auc_male = roc_auc_score(final_df[final_df['Geslacht'] == 1]['label'], final_df[final_df['Geslacht'] == 1]['final_prediction'])\n",
    "\n",
    "# Calculate the AUC for females (Geslacht = 0)\n",
    "auc_female = roc_auc_score(final_df[final_df['Geslacht'] == 0]['label'], final_df[final_df['Geslacht'] == 0]['final_prediction'])\n",
    "\n",
    "\n",
    "# Print the calculated metrics separately for both classes\n",
    "print(f\"Accuracy (Overall): {accuracy_positive:.4f}\")\n",
    "print(f\"Precision (Positive): {precision_positive:.4f}\")\n",
    "print(f\"Recall (Positive): {recall_positive:.4f}\")\n",
    "print(f\"F1 Score (Positive): {f1_positive:.4f}\")\n",
    "print(f\"Precision (Negative): {precision_negative:.4f}\")\n",
    "print(f\"Recall (Negative): {recall_negative:.4f}\")\n",
    "print(f\"F1 Score (Negative): {f1_negative:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"AUC (Male): {auc_male:.4f}\")\n",
    "print(f\"AUC (Female): {auc_female:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7c14b-b14e-4aea-9300-ab6f49ab52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix for the entire dataset\n",
    "cm = confusion_matrix(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate TPR and FPR for male (Geslacht = 1)\n",
    "male_indices = final_df['Geslacht'] == 1\n",
    "cm_male = confusion_matrix(final_df[male_indices]['label'], final_df[male_indices]['final_prediction'])\n",
    "\n",
    "tpr_male = cm_male[1, 1] / (cm_male[1, 0] + cm_male[1, 1])\n",
    "fpr_male = cm_male[0, 1] / (cm_male[0, 0] + cm_male[0, 1])\n",
    "\n",
    "# Calculate TPR and FPR for female (Geslacht = 0)\n",
    "female_indices = final_df['Geslacht'] == 0\n",
    "cm_female = confusion_matrix(final_df[female_indices]['label'], final_df[female_indices]['final_prediction'])\n",
    "\n",
    "tpr_female = cm_female[1, 1] / (cm_female[1, 0] + cm_female[1, 1])\n",
    "fpr_female = cm_female[0, 1] / (cm_female[0, 0] + cm_female[0, 1])\n",
    "\n",
    "# Print the calculated metrics separately for both classes\n",
    "print(f\"TPR (Male): {tpr_male:.4f}\")\n",
    "print(f\"TPR (Female): {tpr_female:.4f}\")\n",
    "print(f\"FPR (Male): {fpr_male:.4f}\")\n",
    "print(f\"FPR (Female): {fpr_female:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12575242-f790-4e76-9489-e9039c78f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['combined'] = final_df['Geslacht'].astype(str) + '_' + final_df['label'].astype(str) + '_' + final_df['final_prediction'].astype(str)\n",
    "\n",
    "# Get the count of combinations\n",
    "combination_counts = final_df['combined'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Combined Counts:\")\n",
    "print(combination_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfc4d5-8b1f-4ebb-b7d1-78f1be4e6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('hpc_space/Results/BERTje/' + 'BERTje_genderneutral_predictions_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1e815-8303-4ea1-a40a-b7c63a6c69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into first_half and second_half\n",
    "first_half = final_df.iloc[:len(final_df) // 2]\n",
    "second_half = final_df.iloc[len(final_df) // 2:]\n",
    "\n",
    "first_half.reset_index(drop=True, inplace=True)\n",
    "second_half.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Compare the 'final_prediction' values in the two halves and calculate value counts\n",
    "mismatch_counts = (first_half['final_prediction'] != second_half['final_prediction']).value_counts()\n",
    "\n",
    "# Create a DataFrame to display the mismatch counts\n",
    "mismatches = pd.DataFrame({'Mismatches': mismatch_counts})\n",
    "print(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfdb10-bfb0-418b-b2f7-f8bc573e68c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrabiasKernelJoppe",
   "language": "python",
   "name": "vrabiaskerneljoppe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
