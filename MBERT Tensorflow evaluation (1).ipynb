{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e54c36-e28e-4d70-acd3-659d447b6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:40:35.341948: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-04 19:40:35.384729: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 19:40:35.384771: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 19:40:35.384798: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 19:40:35.393362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956622ee-976e-4f35-9732-45db2311cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('hpc_space/test_data_5_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a471e7f-3b58-4bed-8fce-05d254b82464",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('hpc_space/val_data_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45443d42-a310-43ef-a14e-781b8db1b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(text):\n",
    "    text = re.sub(\"'\", \"\", text)\n",
    "    text = re.sub(\"(\\\\W)+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d5f70a-2b82-4fa1-bdb8-7030f9307be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['text'] = test_data.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384480e6-a066-4d60-8918-af6ceff1f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['text'] = val_data.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a69390-8b7c-4796-aef5-74c988b6bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_gendered_words(text, gender):\n",
    "#     gendered_word_mapping = {\n",
    "#         0: {\"zij\": \"hij\", \"Zij\": \"Hij\", \"ze\": \"hij\", \"Ze\": \"Hij\", \"haar\": \"hem\", \"Haar\": \"Hem\", \"mw\": \"dhr\", \"Mw\": \"Dhr\", \"vrouw\": \"man\", \"Vrouw\": \"Man\", \"patiente\": \"patient\", \"Patiente\": \"Patient\", \"mevrouw\": \"meneer\", \"Mevrouw\": \"Meneer\", \"mevr\": \"mr\", \"Mevr\": \"Mr\", \"meisje\": \"jongen\", \"Meisje\": \"Jongen\", \"dame\": \"heer\", \"Dame\": \"Heer\"},\n",
    "#         1: {\"hij\": \"zij\", \"Hij\": \"Zij\", \"hem\": \"haar\", \"Hem\": \"Haar\", \"zijn\": \"haar\", \"Zijn\":\"Haar\", \"dhr\": \"mw\", \"Dhr\": \"Mw\", \"man\": \"vrouw\", \"Man\": \"Vrouw\", \"patient\": \"patiente\", \"Patient\": \"Patiente\", \"meneer\": \"mevrouw\", \"Meneer\": \"Mevrouw\", \"mr\": \"mevr\", \"Mr\": \"Mevr\", \"jongen\": \"meisje\", \"Jongen\": \"Meisje\", \"heer\": \"dame\", \"Heer\": \"Dame\", \"hr\":\"mw\", \"Hr\": \"Mw\"},\n",
    "#     }\n",
    "\n",
    "#     words = text.split()\n",
    "\n",
    "#     for i in range(len(words)):\n",
    "#         word = words[i]\n",
    "#         if word in gendered_word_mapping[gender]:\n",
    "#             words[i] = gendered_word_mapping[gender][word]\n",
    "\n",
    "#     return ' '.join(words)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # Replace gendered words in the 'text' column based on the 'Geslacht' column\n",
    "#     test_data['text'] = test_data.apply(lambda row: replace_gendered_words(row['text'], row['Geslacht']), axis=1)\n",
    "\n",
    "#     # Print the modified DataFrame\n",
    "#     print(\"Modified DataFrame:\")\n",
    "#     print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347d4297-4732-45b2-8276-94fda51709b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['Geslacht'] = test_data['Geslacht'].replace({0: 1, 1: 0})\n",
    "\n",
    "# # Print the modified DataFrame\n",
    "# print(\"Modified DataFrame:\")\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d8cbb27-f217-43c3-8ed4-996c0c3fbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['Combined'] = test_data['Combined'].replace({'0_1': '0_0', '0_0': '0_1', '1_0': '1_1', '1_1': '1_0'})\n",
    "\n",
    "# # Print the modified DataFrame\n",
    "# print(\"Modified DataFrame:\")\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3472cf2c-8a3d-4694-968b-5202bbf00d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_orig = pd.read_csv('hpc_space/MBERT1/test_data_mid_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49601fc6-1d74-42cb-bc83-acb9dcbb3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_orig['text'] = test_data_orig.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ead85f-6baa-476c-9c8a-99dc061e1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.concat([test_data_orig, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9f245b-80ef-4248-ae67-03ddd5940732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "    l_total = []\n",
    "    chunk_size = 500\n",
    "    overlap = 50\n",
    "\n",
    "    words = text1.split()\n",
    "\n",
    "    for start_idx in range(0, len(words), chunk_size - overlap):\n",
    "        end_idx = start_idx + chunk_size\n",
    "        l_parcial = words[start_idx:end_idx]\n",
    "        l_total.append(\" \".join(l_parcial))\n",
    "\n",
    "    return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef148cbe-940b-407c-9852-603c0fb7cc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Geslacht</th>\n",
       "      <th>Combined</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pte en moeder gezien voor pre intake met PERS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[pte en moeder gezien voor pre intake met PERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Overleg met PERSOON 1 psychiater HIC patiente...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[Overleg met PERSOON 1 psychiater HIC patiente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Opnamegesprek dagdienst Aanwezigen patiente p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[Opnamegesprek dagdienst Aanwezigen patiente p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Psychische problemen Opener mimiek dan voorh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0_1</td>\n",
       "      <td>[1 Psychische problemen Opener mimiek dan voor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PERSOON 1 leek bij controle te slapen 1 Psych...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[PERSOON 1 leek bij controle te slapen 1 Psych...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  outcome  Geslacht  \\\n",
       "0   pte en moeder gezien voor pre intake met PERS...        0         0   \n",
       "1   Overleg met PERSOON 1 psychiater HIC patiente...        0         0   \n",
       "2   Opnamegesprek dagdienst Aanwezigen patiente p...        0         0   \n",
       "3  1 Psychische problemen Opener mimiek dan voorh...        0         1   \n",
       "4   PERSOON 1 leek bij controle te slapen 1 Psych...        0         0   \n",
       "\n",
       "  Combined                                         text_split  \n",
       "0      0_0  [pte en moeder gezien voor pre intake met PERS...  \n",
       "1      0_0  [Overleg met PERSOON 1 psychiater HIC patiente...  \n",
       "2      0_0  [Opnamegesprek dagdienst Aanwezigen patiente p...  \n",
       "3      0_1  [1 Psychische problemen Opener mimiek dan voor...  \n",
       "4      0_0  [PERSOON 1 leek bij controle te slapen 1 Psych...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[:, 'text_split'] = test_data['text'].apply(get_split)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f6b0f5-762d-472f-9520-b75b4bd8e1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Geslacht</th>\n",
       "      <th>Combined</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kennedy scores tbv teamoverleg 1 Psychische pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[Kennedy scores tbv teamoverleg 1 Psychische p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Psychische problemen Mw kwam om ongeveer 14 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[1 Psychische problemen Mw kwam om ongeveer 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Psychische problemen Bekend met adhd pdd nos...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[1 Psychische problemen Bekend met adhd pdd no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PERSOON 1 kinder en jeugdpsychiater Jeugd ACT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0_1</td>\n",
       "      <td>[PERSOON 1 kinder en jeugdpsychiater Jeugd ACT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Op verzoek van PERSOON 1 verwijzing 28 01 19 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>[Op verzoek van PERSOON 1 verwijzing 28 01 19 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  outcome  Geslacht  \\\n",
       "0  Kennedy scores tbv teamoverleg 1 Psychische pr...        0         0   \n",
       "1  1 Psychische problemen Mw kwam om ongeveer 14 ...        0         0   \n",
       "2  1 Psychische problemen Bekend met adhd pdd nos...        0         0   \n",
       "3   PERSOON 1 kinder en jeugdpsychiater Jeugd ACT...        0         1   \n",
       "4   Op verzoek van PERSOON 1 verwijzing 28 01 19 ...        0         0   \n",
       "\n",
       "  Combined                                         text_split  \n",
       "0      0_0  [Kennedy scores tbv teamoverleg 1 Psychische p...  \n",
       "1      0_0  [1 Psychische problemen Mw kwam om ongeveer 14...  \n",
       "2      0_0  [1 Psychische problemen Bekend met adhd pdd no...  \n",
       "3      0_1  [PERSOON 1 kinder en jeugdpsychiater Jeugd ACT...  \n",
       "4      0_0  [Op verzoek van PERSOON 1 verwijzing 28 01 19 ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.loc[:, 'text_split'] = val_data['text'].apply(get_split)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96791b6f-e771-4f19-994f-ba13e2f1ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = []\n",
    "test_label_l = []\n",
    "test_index_l = []\n",
    "geslacht_l = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    for l in row['text_split']:\n",
    "        test_l.append(l)\n",
    "        test_label_l.append(row['outcome'])\n",
    "        test_index_l.append(idx)\n",
    "        geslacht_l.append(row['Geslacht'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33d03e1e-01e6-495a-b0ef-c69752907bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "val_geslacht_l = []\n",
    "for idx, row in val_data.iterrows():\n",
    "    for l in row['text_split']:\n",
    "        val_l.append(l)\n",
    "        val_label_l.append(row['outcome'])\n",
    "        val_index_l.append(idx)\n",
    "        val_geslacht_l.append(row['Geslacht'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d7aba7-31df-4d2c-bafd-f15831de90a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Geslacht</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pte en moeder gezien voor pre intake met PERSO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afentoe in het weekend Ketamine geen speed of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bijzijn moeder 4 ADL functies en beroepsmatig ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uit zichzelf contact aan te gaan 3 Risico op a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overleg met PERSOON 1 psychiater HIC patiente ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  Geslacht  \\\n",
       "0  pte en moeder gezien voor pre intake met PERSO...      0         0   \n",
       "1  afentoe in het weekend Ketamine geen speed of ...      0         0   \n",
       "2  bijzijn moeder 4 ADL functies en beroepsmatig ...      0         0   \n",
       "3  uit zichzelf contact aan te gaan 3 Risico op a...      0         0   \n",
       "4  Overleg met PERSOON 1 psychiater HIC patiente ...      0         0   \n",
       "\n",
       "   original_index  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'text':test_l, 'label':test_label_l, 'Geslacht':geslacht_l, 'original_index':test_index_l})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f01215-5643-42ab-a113-fc6d8a24c9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Geslacht</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kennedy scores tbv teamoverleg 1 Psychische pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conrete poging ondernomen Afgelopen dagen uiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gedrag Denken lijkt normofreen coherent inhoud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Psychische problemen Mw kwam om ongeveer 14 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bekend Medicatie bij opname Quetiapine MGA 1d1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  Geslacht  \\\n",
       "0  Kennedy scores tbv teamoverleg 1 Psychische pr...      0         0   \n",
       "1  conrete poging ondernomen Afgelopen dagen uiti...      0         0   \n",
       "2  gedrag Denken lijkt normofreen coherent inhoud...      0         0   \n",
       "3  1 Psychische problemen Mw kwam om ongeveer 14 ...      0         0   \n",
       "4  bekend Medicatie bij opname Quetiapine MGA 1d1...      0         0   \n",
       "\n",
       "   original_index  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({'text':val_l, 'label':val_label_l, 'Geslacht':val_geslacht_l, 'original_index':val_index_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "404fb52d-c6bd-4127-b900-bfa2397b059f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7b47aa473943cabfe1073c6bef0b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c9f48a2-daea-41c5-a2d6-7f5da62183a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092a61a8427f437ca5cf15485f9c199a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbd0ec980d94bb88e40668b66092df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208bdd9c5b0947d89a7c38080ff05928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/715k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50823a8ab08d4c89a07b543a4f723ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "test_texts = test_df['text'].tolist()\n",
    "encoded_test = tokenizer(test_texts, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66329185-64cb-4c25-8e6b-f143acc364a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f41e7ace334c088e1c04ea31a23981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51a572ade634a16b6cf378fc2ccbecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/437M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:41:26.537580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14791 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2023-12-04 19:41:26.918525: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at JoppeK/BERTje_augmented_5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "# Set batch size and sequence length\n",
    "\n",
    "batch_size = 16\n",
    "max_seq_length = 512\n",
    "\n",
    "test_df_with_predictions = test_df.copy()\n",
    "\n",
    "# Convert PyTorch tensors to TensorFlow tensors in batches\n",
    "num_samples = len(test_texts)\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_input_ids = tf.convert_to_tensor(encoded_test['input_ids'][i:i+batch_size])\n",
    "    batch_attention_mask = tf.convert_to_tensor(encoded_test['attention_mask'][i:i+batch_size])\n",
    "    batch_token_type_ids = tf.convert_to_tensor(encoded_test['token_type_ids'][i:i+batch_size])\n",
    "\n",
    "    # Get model predictions for the current batch\n",
    "\n",
    "    logits = model(batch_input_ids, attention_mask=batch_attention_mask, token_type_ids=batch_token_type_ids).logits\n",
    "\n",
    "    # Convert logits to probabilities and labels\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    predicted_labels = tf.argmax(probs, axis=1)\n",
    "\n",
    "    # Update test_df_with_predictions with the current batch's predictions\n",
    "    batch_indices = list(range(i, min(i + batch_size, num_samples)))\n",
    "    for idx, label, prob in zip(batch_indices, predicted_labels.numpy(), np.max(probs.numpy(), axis=1)):\n",
    "        test_df_with_predictions.at[idx, 'predicted_label'] = label\n",
    "        test_df_with_predictions.at[idx, 'predicted_probability'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5a22c62-05be-499a-99ce-2fc7034ef73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions.drop(['text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d1e8efc-8f60-4f97-aa12-c5682bfcdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions.rename(columns={'predicted_probability': 'predicted_probabilities'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e7fa69f-9d91-43e1-8d24-d9c71a0e8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  Geslacht  original_index  predicted_label  \\\n",
      "0         0         0               0              0.0   \n",
      "1         0         0               0              0.0   \n",
      "2         0         0               0              0.0   \n",
      "3         0         0               0              0.0   \n",
      "4         0         0               1              0.0   \n",
      "...     ...       ...             ...              ...   \n",
      "9825      0         1            1477              0.0   \n",
      "9826      0         1            1477              0.0   \n",
      "9827      0         1            1477              0.0   \n",
      "9828      0         1            1477              0.0   \n",
      "9829      0         1            1477              0.0   \n",
      "\n",
      "      predicted_probabilities  \n",
      "0                    0.998639  \n",
      "1                    0.999000  \n",
      "2                    0.996818  \n",
      "3                    0.999128  \n",
      "4                    0.997658  \n",
      "...                       ...  \n",
      "9825                 0.998578  \n",
      "9826                 0.999252  \n",
      "9827                 0.589075  \n",
      "9828                 0.999006  \n",
      "9829                 0.999115  \n",
      "\n",
      "[9830 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df_with_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed9e69e1-4b26-4f82-8c96-5933b515fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions.to_csv('BERTje_augmented5_chunk_augmentedtest_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6418325-1996-4002-9022-50c566e20592",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "val_texts = val_df['text'].tolist()\n",
    "encoded_val = tokenizer(val_texts, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80957b89-41a6-428a-8256-5b3559cc6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at JoppeK/BERTje_augmented_5 were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at JoppeK/BERTje_augmented_5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"JoppeK/BERTje_augmented_5\")\n",
    "# Set batch size and sequence length\n",
    "\n",
    "batch_size = 16\n",
    "max_seq_length = 512\n",
    "\n",
    "val_df_with_predictions = val_df.copy()\n",
    "\n",
    "# Convert PyTorch tensors to TensorFlow tensors in batches\n",
    "num_samples = len(val_texts)\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch_input_ids = tf.convert_to_tensor(encoded_val['input_ids'][i:i+batch_size])\n",
    "    batch_attention_mask = tf.convert_to_tensor(encoded_val['attention_mask'][i:i+batch_size])\n",
    "    batch_token_type_ids = tf.convert_to_tensor(encoded_val['token_type_ids'][i:i+batch_size])\n",
    "\n",
    "    # Get model predictions for the current batch\n",
    "\n",
    "    logits = model(batch_input_ids, attention_mask=batch_attention_mask, token_type_ids=batch_token_type_ids).logits\n",
    "\n",
    "    # Convert logits to probabilities and labels\n",
    "    probs = tf.nn.softmax(logits, axis=1)\n",
    "    predicted_labels = tf.argmax(probs, axis=1)\n",
    "\n",
    "    # Update val_df_with_predictions with the current batch's predictions\n",
    "    batch_indices = list(range(i, min(i + batch_size, num_samples)))\n",
    "    for idx, label, prob in zip(batch_indices, predicted_labels.numpy(), np.max(probs.numpy(), axis=1)):\n",
    "        val_df_with_predictions.at[idx, 'predicted_label'] = label\n",
    "        val_df_with_predictions.at[idx, 'predicted_probability'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "195a5c3c-f0ce-423b-a295-fb27de50f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_with_predictions.drop(['text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "321f999c-d330-4f27-8730-18fa1a220fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_with_predictions.rename(columns={'predicted_probability': 'predicted_probabilities'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f21e1138-85a4-4e3b-b198-ed0014e328d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  Geslacht  original_index  predicted_label  \\\n",
      "0         0         0               0              0.0   \n",
      "1         0         0               0              0.0   \n",
      "2         0         0               0              0.0   \n",
      "3         0         0               1              0.0   \n",
      "4         0         0               1              0.0   \n",
      "...     ...       ...             ...              ...   \n",
      "5003      0         1             737              0.0   \n",
      "5004      0         1             737              0.0   \n",
      "5005      0         0             738              0.0   \n",
      "5006      0         0             738              0.0   \n",
      "5007      0         0             738              0.0   \n",
      "\n",
      "      predicted_probabilities  \n",
      "0                    0.993488  \n",
      "1                    0.996100  \n",
      "2                    0.998200  \n",
      "3                    0.998124  \n",
      "4                    0.998875  \n",
      "...                       ...  \n",
      "5003                 0.999305  \n",
      "5004                 0.997405  \n",
      "5005                 0.998700  \n",
      "5006                 0.998138  \n",
      "5007                 0.998682  \n",
      "\n",
      "[5008 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(val_df_with_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9f47a74-5036-4e05-9b1b-048e5e83b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_with_predictions.to_csv('BERTje_augmented5_chunk_val_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524c36f-3ec0-46c1-9f5b-0895d3e61c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bc2bd-720b-423e-b6c2-d5b1fc9506d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac406945-b06e-4117-998b-456b0fcab3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_predictions['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5ae1c-1f64-41a7-8e2c-20c24a01da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the predicted labels based on 'original_index'\n",
    "grouped_predictions = test_df_with_predictions.groupby('original_index')['predicted_label'].apply(list)\n",
    "\n",
    "# Merge the grouped predictions back to the original DataFrame\n",
    "merged_df = test_df_with_predictions.merge(grouped_predictions, left_on='original_index', right_index=True)\n",
    "\n",
    "# Rename the new column\n",
    "merged_df.rename(columns={'predicted_label_y': 'grouped_predicted_labels'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df.drop(['text', 'predicted_label_x'], axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicates and keep only one row per unique original_index\n",
    "final_df = merged_df.drop_duplicates(subset='original_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a54c7-95f0-43ba-b98f-1fd9ae8b1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('hpc_space/Results/temp/' + 'BERTje_genderneutral_predictions_1_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9939f9-5a44-4b54-9b52-084dd2f0bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"hpc_space/Results/temp/BERTje_genderneutral_predictions_1_temp.csv\")\n",
    "# Convert string representations of lists to actual lists\n",
    "final_df['grouped_predicted_labels'] = final_df['grouped_predicted_labels'].apply(eval)\n",
    "\n",
    "# Function to determine final prediction\n",
    "def calculate_final_prediction(grouped_labels):\n",
    "    # Calculate the proportion of 1s in the grouped labels\n",
    "    proportion_of_ones = grouped_labels.count(1) / len(grouped_labels)\n",
    "\n",
    "    # Set the threshold for making the final prediction\n",
    "    threshold = 0.25\n",
    "\n",
    "    # Make the final prediction based on the proportion\n",
    "    if proportion_of_ones > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to each row and create a new column for final predictions\n",
    "final_df['final_prediction'] = final_df['grouped_predicted_labels'].apply(calculate_final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5d061-6ec8-438d-8427-f909beb73a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Calculate accuracy for the positive class (label = 1)\n",
    "accuracy_positive = accuracy_score(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate precision for the positive class (label = 1)\n",
    "precision_positive = precision_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate recall for the positive class (label = 1)\n",
    "recall_positive = recall_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate F1 score for the positive class (label = 1)\n",
    "f1_positive = f1_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate precision for the negative class (label = 0)\n",
    "precision_negative = precision_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate recall for the negative class (label = 0)\n",
    "recall_negative = recall_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate F1 score for the negative class (label = 0)\n",
    "f1_negative = f1_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate the AUC for males (Geslacht = 1)\n",
    "auc_male = roc_auc_score(final_df[final_df['Geslacht'] == 1]['label'], final_df[final_df['Geslacht'] == 1]['final_prediction'])\n",
    "\n",
    "# Calculate the AUC for females (Geslacht = 0)\n",
    "auc_female = roc_auc_score(final_df[final_df['Geslacht'] == 0]['label'], final_df[final_df['Geslacht'] == 0]['final_prediction'])\n",
    "\n",
    "\n",
    "# Print the calculated metrics separately for both classes\n",
    "print(f\"Accuracy (Overall): {accuracy_positive:.4f}\")\n",
    "print(f\"Precision (Positive): {precision_positive:.4f}\")\n",
    "print(f\"Recall (Positive): {recall_positive:.4f}\")\n",
    "print(f\"F1 Score (Positive): {f1_positive:.4f}\")\n",
    "print(f\"Precision (Negative): {precision_negative:.4f}\")\n",
    "print(f\"Recall (Negative): {recall_negative:.4f}\")\n",
    "print(f\"F1 Score (Negative): {f1_negative:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"AUC (Male): {auc_male:.4f}\")\n",
    "print(f\"AUC (Female): {auc_female:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7c14b-b14e-4aea-9300-ab6f49ab52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix for the entire dataset\n",
    "cm = confusion_matrix(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate TPR and FPR for male (Geslacht = 1)\n",
    "male_indices = final_df['Geslacht'] == 1\n",
    "cm_male = confusion_matrix(final_df[male_indices]['label'], final_df[male_indices]['final_prediction'])\n",
    "\n",
    "tpr_male = cm_male[1, 1] / (cm_male[1, 0] + cm_male[1, 1])\n",
    "fpr_male = cm_male[0, 1] / (cm_male[0, 0] + cm_male[0, 1])\n",
    "\n",
    "# Calculate TPR and FPR for female (Geslacht = 0)\n",
    "female_indices = final_df['Geslacht'] == 0\n",
    "cm_female = confusion_matrix(final_df[female_indices]['label'], final_df[female_indices]['final_prediction'])\n",
    "\n",
    "tpr_female = cm_female[1, 1] / (cm_female[1, 0] + cm_female[1, 1])\n",
    "fpr_female = cm_female[0, 1] / (cm_female[0, 0] + cm_female[0, 1])\n",
    "\n",
    "# Print the calculated metrics separately for both classes\n",
    "print(f\"TPR (Male): {tpr_male:.4f}\")\n",
    "print(f\"TPR (Female): {tpr_female:.4f}\")\n",
    "print(f\"FPR (Male): {fpr_male:.4f}\")\n",
    "print(f\"FPR (Female): {fpr_female:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12575242-f790-4e76-9489-e9039c78f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['combined'] = final_df['Geslacht'].astype(str) + '_' + final_df['label'].astype(str) + '_' + final_df['final_prediction'].astype(str)\n",
    "\n",
    "# Get the count of combinations\n",
    "combination_counts = final_df['combined'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Combined Counts:\")\n",
    "print(combination_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfc4d5-8b1f-4ebb-b7d1-78f1be4e6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('hpc_space/Results/BERTje/' + 'BERTje_genderneutral_predictions_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1e815-8303-4ea1-a40a-b7c63a6c69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into first_half and second_half\n",
    "first_half = final_df.iloc[:len(final_df) // 2]\n",
    "second_half = final_df.iloc[len(final_df) // 2:]\n",
    "\n",
    "first_half.reset_index(drop=True, inplace=True)\n",
    "second_half.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Compare the 'final_prediction' values in the two halves and calculate value counts\n",
    "mismatch_counts = (first_half['final_prediction'] != second_half['final_prediction']).value_counts()\n",
    "\n",
    "# Create a DataFrame to display the mismatch counts\n",
    "mismatches = pd.DataFrame({'Mismatches': mismatch_counts})\n",
    "print(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfdb10-bfb0-418b-b2f7-f8bc573e68c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrabiasKernelJoppe",
   "language": "python",
   "name": "vrabiaskerneljoppe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
