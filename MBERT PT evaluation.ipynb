{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3856bc-d313-48f0-8ccf-cd6ee3665615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea4bf6-e786-4c1b-8ec5-094fe1dace85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838a855-f3fc-44c3-a6e0-f11c0bcfee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ceabc5-2032-442c-96ca-5ce990e4cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('hpc_space/test_data_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ebe6d3-36b9-4957-83b7-b5bbaa3ae62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(text):\n",
    "    text = re.sub(\"'\", \"\", text)\n",
    "    text = re.sub(\"(\\\\W)+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33106d5-30ec-420b-b0ac-7fe5f1ed00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['text'] = test_data.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb88a4-0355-44ab-94f2-e94f91dcbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b4ed9-d7fb-47a3-b428-d1972727fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_gendered_words(text, gender):\n",
    "    gendered_word_mapping = {\n",
    "        0: {\"zij\": \"hij\", \"Zij\": \"Hij\", \"ze\": \"hij\", \"Ze\": \"Hij\", \"haar\": \"hem\", \"Haar\": \"Hem\", \"mw\": \"dhr\", \"Mw\": \"Dhr\", \"vrouw\": \"man\", \"Vrouw\": \"Man\", \"patiente\": \"patient\", \"Patiente\": \"Patient\", \"mevrouw\": \"meneer\", \"Mevrouw\": \"Meneer\", \"mevr\": \"mr\", \"Mevr\": \"Mr\", \"meisje\": \"jongen\", \"Meisje\": \"Jongen\", \"dame\": \"heer\", \"Dame\": \"Heer\"},\n",
    "        1: {\"hij\": \"zij\", \"Hij\": \"Zij\", \"hem\": \"haar\", \"Hem\": \"Haar\", \"zijn\": \"haar\", \"Zijn\":\"Haar\", \"dhr\": \"mw\", \"Dhr\": \"Mw\", \"man\": \"vrouw\", \"Man\": \"Vrouw\", \"patient\": \"patiente\", \"Patient\": \"Patiente\", \"meneer\": \"mevrouw\", \"Meneer\": \"Mevrouw\", \"mr\": \"mevr\", \"Mr\": \"Mevr\", \"jongen\": \"meisje\", \"Jongen\": \"Meisje\", \"heer\": \"dame\", \"Heer\": \"Dame\", \"hr\":\"mw\", \"Hr\": \"Mw\"},\n",
    "    }\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        if word in gendered_word_mapping[gender]:\n",
    "            words[i] = gendered_word_mapping[gender][word]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Replace gendered words in the 'text' column based on the 'Geslacht' column\n",
    "    test_data['text'] = test_data.apply(lambda row: replace_gendered_words(row['text'], row['Geslacht']), axis=1)\n",
    "\n",
    "    # Print the modified DataFrame\n",
    "    print(\"Modified DataFrame:\")\n",
    "    print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b5880-1088-4a7b-8e3f-a155eae5b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Geslacht'] = test_data['Geslacht'].replace({0: 1, 1: 0})\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(\"Modified DataFrame:\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5a96b-f50a-415c-b565-c95e8b24706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Combined'] = test_data['Combined'].replace({'0_1': '0_0', '0_0': '0_1', '1_0': '1_1', '1_1': '1_0'})\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(\"Modified DataFrame:\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa62330-bb3e-452c-bc3f-04b914f9a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig = pd.read_csv('hpc_space/test_data_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d605f88-5ed2-4638-84c1-1b14a72c7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig['text'] = test_data_orig.text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84adb9b4-8f46-4069-a9ea-94e76e97edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4b4ca-e36f-4207-932f-a7a38cb39cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data_orig, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a34664-5e2a-4c62-8ebd-9177bc7554fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"test_data_5_augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab9d61-651d-4c73-88ed-a513668e004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499ac2a-ea16-4e88-ac9e-75e75dee07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_data_augmented_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ef655-cd8e-4c27-8efe-d7576d4bac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "    l_total = []\n",
    "    chunk_size = 500\n",
    "    overlap = 50\n",
    "\n",
    "    words = text1.split()\n",
    "\n",
    "    for start_idx in range(0, len(words), chunk_size - overlap):\n",
    "        end_idx = start_idx + chunk_size\n",
    "        l_parcial = words[start_idx:end_idx]\n",
    "        l_total.append(\" \".join(l_parcial))\n",
    "\n",
    "    return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a23805-62d3-4692-aa99-466721488b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:, 'text_split'] = test_data['text'].apply(get_split)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9af66-05f6-4672-860a-a65ebbab5e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = []\n",
    "test_label_l = []\n",
    "test_index_l = []\n",
    "geslacht_l = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    for l in row['text_split']:\n",
    "        test_l.append(l)\n",
    "        test_label_l.append(row['outcome'])\n",
    "        test_index_l.append(idx)\n",
    "        geslacht_l.append(row['Geslacht'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4b5b2-d775-4d84-8578-1437e3d5a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'text':test_l, 'label':test_label_l, 'Geslacht':geslacht_l, 'original_index':test_index_l})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab9477-3ede-475e-9b23-6a2b08d87a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['label'].tolist()\n",
    "test_original_indices = test_df['original_index'].tolist()\n",
    "test_gender = test_df['Geslacht'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30120b-1785-47f7-82fb-aaa0ff853cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a60df-84c3-4aa2-ae87-959ca9253463",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"JoppeK/MBERT_augmented_5\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"JoppeK/MBERT_augmented_5\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc131d-87eb-44f2-8045-03c572c6da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ca201-f030-48b1-9592-6deb5e242125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(test_encodings['input_ids']),\n",
    "    torch.tensor(test_encodings['token_type_ids']),\n",
    "    torch.tensor(test_encodings['attention_mask'])\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a4fd9-4e5a-4cfc-ab84-8cfec8819a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode and move it to the GPU\n",
    "model = model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "    input_ids, token_type_ids, attention_mask = batch\n",
    "    input_ids = input_ids.to('cuda')\n",
    "    token_type_ids = token_type_ids.to('cuda')\n",
    "    attention_mask = attention_mask.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    probabilities = logits.softmax(dim=1)\n",
    "\n",
    "    # Get the predicted class (0 or 1) based on the highest probability\n",
    "    predicted_class = probabilities.argmax(dim=1)\n",
    "\n",
    "    # Append the predicted classes to the predictions list\n",
    "    predictions.extend(predicted_class.tolist())\n",
    "\n",
    "# Now, 'predictions' contains the predicted classes for your test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f56979-71b9-4950-8a53-8323f51191da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the original test DataFrame with the predictions\n",
    "test_df['predicted_label'] = predictions\n",
    "\n",
    "# Create a new DataFrame with the relevant columns\n",
    "result_df = test_df[['original_index', 'Geslacht', 'label', 'predicted_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea8ebd-4f80-4b1b-876d-fb42b6d21477",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac078f2a-120c-4eb5-809e-4394f44752b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the predicted labels based on 'original_index'\n",
    "grouped_predictions = result_df.groupby('original_index')['predicted_label'].apply(list)\n",
    "\n",
    "# Merge the grouped predictions back to the original DataFrame\n",
    "merged_df = result_df.merge(grouped_predictions, left_on='original_index', right_index=True)\n",
    "\n",
    "# Rename the new column\n",
    "merged_df.rename(columns={'predicted_label_y': 'grouped_predicted_labels'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df.drop(['predicted_label_x'], axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicates and keep only one row per unique original_index\n",
    "final_df = merged_df.drop_duplicates(subset='original_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792dcd10-45cf-47a3-8814-95f127485e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('hpc_space/Results/temp/' + 'MBERT_augmented_predictions_5_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b4413-1a27-4652-a578-4cf7867d8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"hpc_space/Results/temp/MBERT_augmented_predictions_5_temp.csv\")\n",
    "# Convert string representations of lists to actual lists\n",
    "final_df['grouped_predicted_labels'] = final_df['grouped_predicted_labels'].apply(eval)\n",
    "\n",
    "# Function to determine final prediction\n",
    "def calculate_final_prediction(grouped_labels):\n",
    "    # Calculate the proportion of 1s in the grouped labels\n",
    "    proportion_of_ones = grouped_labels.count(1) / len(grouped_labels)\n",
    "\n",
    "    # Set the threshold for making the final prediction\n",
    "    threshold = 0.25\n",
    "\n",
    "    # Make the final prediction based on the proportion\n",
    "    if proportion_of_ones > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to each row and create a new column for final predictions\n",
    "final_df['final_prediction'] = final_df['grouped_predicted_labels'].apply(calculate_final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c746f2a-9349-4077-8729-25263379930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Calculate accuracy for the positive class (label = 1)\n",
    "accuracy_positive = accuracy_score(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate precision for the positive class (label = 1)\n",
    "precision_positive = precision_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate recall for the positive class (label = 1)\n",
    "recall_positive = recall_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate F1 score for the positive class (label = 1)\n",
    "f1_positive = f1_score(final_df['label'], final_df['final_prediction'], pos_label=1)\n",
    "\n",
    "# Calculate precision for the negative class (label = 0)\n",
    "precision_negative = precision_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate recall for the negative class (label = 0)\n",
    "recall_negative = recall_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate F1 score for the negative class (label = 0)\n",
    "f1_negative = f1_score(final_df['label'], final_df['final_prediction'], pos_label=0)\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate the AUC for males (Geslacht = 1)\n",
    "auc_male = roc_auc_score(final_df[final_df['Geslacht'] == 1]['label'], final_df[final_df['Geslacht'] == 1]['final_prediction'])\n",
    "\n",
    "# Calculate the AUC for females (Geslacht = 0)\n",
    "auc_female = roc_auc_score(final_df[final_df['Geslacht'] == 0]['label'], final_df[final_df['Geslacht'] == 0]['final_prediction'])\n",
    "\n",
    "\n",
    "# Print the calculated metrics separately for both classes\n",
    "print(f\"Accuracy (Overall): {accuracy_positive:.4f}\")\n",
    "print(f\"Precision (Positive): {precision_positive:.4f}\")\n",
    "print(f\"Recall (Positive): {recall_positive:.4f}\")\n",
    "print(f\"F1 Score (Positive): {f1_positive:.4f}\")\n",
    "print(f\"Precision (Negative): {precision_negative:.4f}\")\n",
    "print(f\"Recall (Negative): {recall_negative:.4f}\")\n",
    "print(f\"F1 Score (Negative): {f1_negative:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"AUC (Male): {auc_male:.4f}\")\n",
    "print(f\"AUC (Female): {auc_female:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d8a39-dbdf-4da1-9eae-c9bcc530dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix for the entire dataset\n",
    "cm = confusion_matrix(final_df['label'], final_df['final_prediction'])\n",
    "\n",
    "# Calculate TPR and FPR for male (Geslacht = 1)\n",
    "male_indices = final_df['Geslacht'] == 1\n",
    "cm_male = confusion_matrix(final_df[male_indices]['label'], final_df[male_indices]['final_prediction'])\n",
    "\n",
    "tpr_male = cm_male[1, 1] / (cm_male[1, 0] + cm_male[1, 1])\n",
    "fpr_male = cm_male[0, 1] / (cm_male[0, 0] + cm_male[0, 1])\n",
    "\n",
    "# Calculate TPR and FPR for female (Geslacht = 0)\n",
    "female_indices = final_df['Geslacht'] == 0\n",
    "cm_female = confusion_matrix(final_df[female_indices]['label'], final_df[female_indices]['final_prediction'])\n",
    "\n",
    "tpr_female = cm_female[1, 1] / (cm_female[1, 0] + cm_female[1, 1])\n",
    "fpr_female = cm_female[0, 1] / (cm_female[0, 0] + cm_female[0, 1])\n",
    "\n",
    "# Print the calculated metrics separately for both classes\n",
    "print(f\"TPR (Male): {tpr_male:.4f}\")\n",
    "print(f\"TPR (Female): {tpr_female:.4f}\")\n",
    "print(f\"FPR (Male): {fpr_male:.4f}\")\n",
    "print(f\"FPR (Female): {fpr_female:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f023060-80b7-4d59-ac83-8201c3774129",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['combined'] = final_df['Geslacht'].astype(str) + '_' + final_df['label'].astype(str) + '_' + final_df['final_prediction'].astype(str)\n",
    "\n",
    "# Get the count of combinations\n",
    "combination_counts = final_df['combined'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Combined Counts:\")\n",
    "print(combination_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c47a9-69d8-41e7-ab7f-9567e8238225",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('hpc_space/Results/MBERT/' + 'MBERT_augmented_predictions_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdec55-a96c-482b-859d-8b2c99450512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into first_half and second_half\n",
    "first_half = final_df.iloc[:len(final_df) // 2]\n",
    "second_half = final_df.iloc[len(final_df) // 2:]\n",
    "\n",
    "first_half.reset_index(drop=True, inplace=True)\n",
    "second_half.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Compare the 'final_prediction' values in the two halves and calculate value counts\n",
    "mismatch_counts = (first_half['final_prediction'] != second_half['final_prediction']).value_counts()\n",
    "\n",
    "# Create a DataFrame to display the mismatch counts\n",
    "mismatches = pd.DataFrame({'Mismatches': mismatch_counts})\n",
    "print(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78083231-9661-47f3-b6e1-971cfecab000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrabiasKernelJoppe",
   "language": "python",
   "name": "vrabiaskerneljoppe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
